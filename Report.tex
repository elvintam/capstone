% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{article}
\usepackage{lmodern}
\usepackage{amsmath}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
  \usepackage{amssymb}
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={Data Science: Capstone Project - MovieLens},
  pdfauthor={Elvin Tam},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage[margin=1in]{geometry}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
\ifluatex
  \usepackage{selnolig}  % disable illegal ligatures
\fi

\title{Data Science: Capstone Project - MovieLens}
\author{Elvin Tam}
\date{3/10/2021}

\begin{document}
\maketitle

\hypertarget{introduction}{%
\section{Introduction}\label{introduction}}

In this report, our goal is to predict the movie rating by using a
machine learning algorithm. The data set is coming from MovieLens with
about 10M rows of userId, movieId, rating, timestamp, title and genres.
Movies are released from early 20th century till 2008. Movie rating are
made by user from 1995 to 2009.

Data cleaning is applied to the original data following with data
exploration. 4 major effects are identified. Our approach is using
normalization to these global effects on baseline rating and
regularization (by tuning parameter on lambda) to penalize large
estimates that come from small sample size.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Movie specific effect
\item
  User specific effect
\item
  Genre specific effect
\item
  Rate per Year specific effect
\end{enumerate}

The evaluation of algorithm is based on root mean squared error (RMSE)
of predicted rating against actual rating. Algorithm is trained on train
set and being test on test set. Final RMSE is presented basing the on
the final hold-out validation set with result in the tier of ``RMSE
\textless{} 0.86490''.

\hypertarget{method}{%
\section{Method}\label{method}}

\hypertarget{data-cleaning}{%
\subsection{1. Data Cleaning}\label{data-cleaning}}

edx data set contains 6 columns (userId, movieId, rating, timestamp,
title and genres).

In order to facilitate movie rating prediction modelling, pre-process
data cleaning is applied to edx data set prior to data partition
creation. Title column is split to title and year. Timestamp which is
number of second since 1-Jan-1970 00:00:00 is converted to date. Using
createDataPatition function from caret package to create train set and
test set with percentage of 80\% and 20\% correspondingly. Semi-join by
movieId and userId is applied to test set to avoid NA situation when
joining is applied to test set in validation stage.
{[}head(train\_set){]}

\hypertarget{data-exploration}{%
\subsection{2. Data Exploration}\label{data-exploration}}

From train set, we can simplify find the average rating across all
movies and all users is μ = 3.51 and the end year of all movies is 2008.
To avoid dividing by zero in rate per year calculation, we are using
2009 (2008 + 1) as the end year.

{[}mu, maxyear{]}

\hypertarget{a.-movie-specific-effect-b_i}{%
\subsubsection{A. Movie specific effect
(b\_i)}\label{a.-movie-specific-effect-b_i}}

From below chart, we can find that average movie rating adjusted by μ is
at -0.32 with distribution skewed to the left side.\\
{[}code for average{]} {[}Chart{]}

\hypertarget{b.-user-specific-effect-b_u}{%
\subsubsection{B. User specific effect
(b\_u)}\label{b.-user-specific-effect-b_u}}

On the other hand, we can find that average user rating adjusted by μ is
0.10 with more user giving above average rating. {[}code for average{]}
{[}Chart{]}

\hypertarget{c.-genre-specific-effect}{%
\paragraph{C. Genre specific effect}\label{c.-genre-specific-effect}}

We are only illustrating the genres with rating more than 20K times in
below chart. We can see that there is clear relation between rating
adjusted by μ and genre. The lowest average rating is coming from
``Comedy \textbar{} Horror'' while ``Crime \textbar{} Mystery \textbar{}
Thriller'' has the highest average rating.

{[}Chart{]}

\hypertarget{d.-rate-per-year-specific-effect-b_r}{%
\subsubsection{D. Rate per Year specific effect
(b\_r)}\label{d.-rate-per-year-specific-effect-b_r}}

From below chart, we can see that the more often a movie is rated per
year, the higher its average rating adjusted by mu (the blue line).
Basing on the observation, a lower value will be given if rate per year
is lower the corresponding rating per year of μ. For details, please
refer to section 3 of modeling approach.

{[}Chart{]}

\hypertarget{modeling-approach}{%
\subsection{3. Modeling Approach}\label{modeling-approach}}

\hypertarget{normalization-of-global-effects}{%
\subsubsection{Normalization of Global
Effects}\label{normalization-of-global-effects}}

We are using the approach of normalization of global effects in this
project. Basing on the above 4 findings, we decompose 4 global effects
starting from assuming the same rating (μ, average rating) across all
movies and all users. The differences is explained by specific effects
from Movie (b\_i) / User (b\_u) / Genre (b\_g) / Rate per Year (b\_r)
and random variation (εu,i).

Yu,i = μ + b\_i + b\_u + b\_g + b\_r + εu,i

Movie / User / Genre effects tables are created by taking average of the
rating minus μ and the other bias one by one. Codes are extracted below.

summarize(b\_i = sum(rating - mu) / (n() + l)) summarize(b\_u =
sum(rating - mu - b\_i) / (n() + l)) summarize(b\_g = sum(rating - mu -
b\_i - b\_u) / (n() + l))

For Rate per Year effect table, a linear regression model
fit\_rateperyear is created. First, we adjust the rating with μ and
above 3 effects and fit the rating with rate per year in a simple linear
regression model. Using the regression model, if rate per year is less
than the corresponding number of rating per year of average rating, we
use model to predict new rating. If not, we keep the original rating.
With this approach, we are trying to lower the prediction of rating
affected by rate per year.

rating = rating - mu - b\_i - b\_u - b\_g

{[}code{]}

\hypertarget{regularization}{%
\subsubsection{Regularization}\label{regularization}}

Movie / User / Genre effects are regularized with λ to penalize large
estimates that come from small sample size with the shrunk prediction. λ
is a tuning parameter using cross-validation to choose minimum RSME on
train set only. This process doesn't apply to Rate per Year effect
because this effect has already penalized the prediction with
lower-than-average Rate per Year. λ of 2.9 is chosen.

summarize(b\_i = sum(rating - mu) / (n() + l)) summarize(b\_u =
sum(rating - mu - b\_i) / (n() + l)) summarize(b\_g = sum(rating - mu -
b\_i - b\_u) / (n() + l))

{[}Chart{]}

\hypertarget{prediction-restraint-and-na-handling-for-movie-user-outside-of-train-set}{%
\subsubsection{Prediction Restraint and NA handling for Movie / User
outside of Train
Set}\label{prediction-restraint-and-na-handling-for-movie-user-outside-of-train-set}}

Since our target is to predict the movie rating which is only from 0 to
5. It is not meaningful to predict a rating less than 0 or greater than
5. As a result, prediction is restrained to 0 to 5 with below code.

mutate(pred = ifelse(pred \textless0, 0, ifelse(pred \textgreater5 , 5,
pred)))

It is possible to encounter a movie or a user in validation set that
does not appear in the train set. Under this scenario, rating of μ is
predicted.

{[}code{]}

\hypertarget{result}{%
\section{Result}\label{result}}

RMSE result for test set is 0.8643338. RMSE result for validation set is
0.8647539. Both results are in the tier of ``RMSE \textless{} 0.86490''
{[}code{]}

The most time-wasting process is regularization since it involves lambda
section with selected values. Wider range and wider increment are
applied first and then narrow the range to 1 and increment to 0.1.

lambdas \textless- seq(1, 10, 1) lambdas \textless- seq(2, 5, 0.25)
lambdas \textless- seq(2.5, 3.5, 0.1)

The second time-wasting process is data cleaning specially on the split
of title and year from the original title column. The main reason is the
separator using Regex to detect the pattern and handle different
scenarios.

\hypertarget{conclusion}{%
\section{Conclusion}\label{conclusion}}

This report is using the approach of Normalization of Global Effects and
Regularization to capture the main effects in the data. Result RMSE is
quite significant in the tier of ``RMSE \textless{} 0.86490'' with
handling the 4 effects of Movie / User / Genre / Rate per Year. We can
find that these baseline effects have clear impact on the rating
distribution under data exploration.

In addition to the baseline effects, more sophisticated models can be
applied, like Neighborhood Model and Matrix factorization. Neighborhood
Model (Movie-Movie approach / User-User approach) can identify similar
movie and user that are similar to each other. Their ratings are closed
to each other. Matrix factorization (SVD / PCA) can identify the latent
factors like coefficient of different genres or relevant impact on big
name serial movies.

\includegraphics{Report_files/figure-latex/pressure-1.pdf}

\end{document}
